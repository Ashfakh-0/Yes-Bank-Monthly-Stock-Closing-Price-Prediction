{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Yes Bank Stock Closing Price Prediction**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression, Random Forest\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Mohammed Ashfakh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -** Yes Bank Stock Closing Price Prediction"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on predicting the monthly closing price of Yes Bank stock using machine learning techniques. The dataset consists of 185 records with five variables: Date, Open, High, Low, and Close. The primary objective of the project was to build a reliable regression model that can accurately forecast the closing price based on historical stock price data.\n",
        "\n",
        "The project began with Exploratory Data Analysis (EDA) to understand the structure and quality of the dataset. Initial checks confirmed that there were no missing values or duplicate records. Descriptive statistics and visualization techniques were used to examine the distribution of stock prices and identify patterns. Correlation analysis revealed a very strong positive linear relationship between Open, High, Low, and Close prices, indicating that these variables are highly influential in predicting the closing price.\n",
        "\n",
        "Two hypothesis tests were conducted to statistically validate relationships in the dataset. Pearson’s correlation test confirmed a significant linear relationship between Open and Close prices, supporting the suitability of regression modeling. Additionally, a t-test was used to examine differences between opening and closing prices. These statistical tests strengthened the reliability of the modeling approach.\n",
        "\n",
        "Outlier detection was performed using boxplots, and the Interquartile Range (IQR) method was applied to identify extreme values. Instead of removing data points, a capping technique was used to reduce the influence of outliers while preserving important information. This ensured model stability without losing valuable stock price patterns.\n",
        "\n",
        "For feature engineering and selection, the Date column was removed as it does not directly contribute to numerical prediction in a regression framework. The Open, High, and Low columns were selected as independent variables due to their strong correlation with the Close price. Data scaling was performed using Standardization to ensure that all features were on a similar scale, which improves regression model performance.\n",
        "\n",
        "Two machine learning models were implemented: Linear Regression and Random Forest Regressor. Linear Regression was chosen as the baseline model because of its simplicity and interpretability. Random Forest was selected to capture potential non-linear relationships and interactions between features.\n",
        "\n",
        "Model evaluation was conducted using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R² Score. Linear Regression achieved an MAE of 4.98, RMSE of 8.52, and an R² score of 0.9913. Random Forest produced comparatively higher error values with an R² score of 0.9793 before tuning. After hyperparameter optimization using GridSearchCV, Random Forest improved slightly, but Linear Regression still outperformed it in terms of accuracy and error reduction.\n",
        "\n",
        "Based on the evaluation metrics, Linear Regression was selected as the final prediction model due to its lower error values and higher explanatory power.\n",
        "\n",
        "Overall, the project demonstrates that stock closing prices can be effectively predicted using regression techniques when strong linear relationships exist in the data. The high R² score indicates strong predictive capability, making the model suitable for supporting financial analysis, investment planning, and risk assessment decisions. The project successfully follows the complete machine learning pipeline, from data preprocessing and statistical validation to model training, evaluation, and optimization."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project is to develop a machine learning model to predict the monthly closing price of Yes Bank stock using historical stock data. The dataset includes Open, High, Low, and Close prices, and the goal is to analyze the relationships among these variables to build an accurate regression model. Accurate prediction of closing prices can support better financial analysis, investment planning, and data-driven decision-making."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv('data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CsZZJkB1rWN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"ROWS:\",df.shape[0])\n",
        "print(\"COLUMNS:\",df.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno\n",
        "plt.figure(figsize=(10,5))\n",
        "msno.bar(df)\n",
        "plt.title(\"Missing values per column\",y=1.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "the given dataset is related to the details of stock price of yes bank, which include 5 columns, date,open,high,low and close. In This data set, we have 185 rows and 5 columns. data type of the date is object type, remainig all are float. In this data set we don't have any duplicate values and missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date: Month and year of the stock price record.\n",
        "\n",
        "Open: Opening price\n",
        "\n",
        "High: Highest price in the day\n",
        "\n",
        "Low: Lowest price in the day\n",
        "\n",
        "Close: Stock price at the end of the month."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting date column\n",
        "df['Date']=pd.to_datetime(df['Date'],format='%b-%y')"
      ],
      "metadata": {
        "id": "q6Yy9XRZev4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.sort_values(by='Date')"
      ],
      "metadata": {
        "id": "tvoDFn4bfc-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "4UIRbT6zhrOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Dq01SCYvgNfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Date column was originally in string format (Jan-20, Feb-20, etc.)\n",
        "\n",
        "Converting it to datetime enable:\n",
        "*   Correct chronological sorting.\n",
        "*   Time-based analysis.\n",
        "\n",
        "Sorted the dataset by Date\n",
        "\n",
        "\n",
        "* Ensures the data is in proper time order.\n",
        "*  Essential for stock price trend analysis and modeling.\n",
        "\n",
        "Reset the index after sorting:\n",
        "Sorting changes the row order but keeps the old index.\n",
        "\n",
        "Resetting the index:\n",
        "\n",
        "*   Creates a clean sequential index\n",
        "*   Improves readability\n",
        "\n",
        "Insights Derived from These Steps\n",
        "\n",
        "\n",
        "\n",
        "*   Chronological consistency achieved\n",
        "*   This makes trend detection reliable\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 univariate"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['Close'], bins=30,kde=True)\n",
        "plt.title('Distribution of Closing Price')\n",
        "plt.xlabel('Closing Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hRs2gMN0r-4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram is ideal for understanding the distribution and frequency of values, helping identify common price ranges and outliers."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Most closing prices fall within a lower price range, indicating a sustained decline\n",
        "\n",
        "->Presence of extreme values shows historical instability in stock performance."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Negative insights: Concentration at lower prices signals reduced valuation and weaker financial health.\n",
        "\n",
        "->Positive impact: Helps long-term investors identify low-price accumulation zones."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Univariate"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplot\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(df[['Open','High','Low','Close']])\n",
        "plt.title('Price Distribution Comparison')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gfSB8oYYxFkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot is chosen because it summarizes the distribution, spread, median, and outliers of the closing price in a compact visual."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->The median closing price indicates the typical market level.\n",
        "\n",
        "->Presence of outliers indicates extreme market events or abnormal trading periods.."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Negative insights:Outliers reflect market instability, which increases investment risk\n",
        "\n",
        "->Positive insight: Identifying outliers helps traders and investors avoid abnormal periods."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - Bivariate"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Line Chart\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df['Date'],df['Close'])\n",
        "plt.title('Yes bank monthly closing price trend')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lkKJeOZK66nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line chart is most suitable for time-dependent data. it show how stock closing price changes over times and help to identify long term trends, cycles and sudden price movements.\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> The closing price shows high volatility over time.\n",
        "\n",
        "->there is extendend period of decline from 2018-2020, indicating a bearish sentiment.\n",
        "\n",
        "-> sharp drop indicating financial or organizational stress affecting yes bank."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive insight: identify volatile periods helps investors avoid high risk entry points and support better timing strategy.\n",
        "\n",
        "negative insight: sharp or extended downward trend indicate loss of investors confidence, whill will lead to trading volume and market capitalization"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 Bivariate"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Line Chart\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df['Date'], df['High'] - df['Low'])\n",
        "plt.title('Monthly Price Volatility (High–Low)')\n",
        "plt.ylabel('Price Range')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gecu7bV79tbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The High–Low spread directly measures monthly volatility, which is critical for risk assessment in stock markets."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Periods with high spread indicate uncertain or unstable market conditions.\n",
        "\n",
        "->Calm periods suggest temporary stability in stock performance."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative impact: High volatility increases investment risk and discourages conservative investors"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap (multivariate)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(df[['Open','High','Low','Close']].corr(), annot=True)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "msxXPV_fFPAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap visually represents the strength of relationship between multiple numerical variables"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Strong positive correlation between Open, High, Low, and Close prices\n",
        "\n",
        "->Indicates internal pricing consistency in the stock(if Open price increase->close,High,low also tend to increase)\n",
        "(if Open price decreases-> close,High,low also tend to decrease)\n",
        "\n",
        "->High correlation confirms data reliability."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code(Multivariate)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(df[['Open','High','Low','Close']])\n",
        "plt.suptitle('Pairplot of Yes bank Stock prices', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rPUYUqMAExxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pairplot is chosen to simultaneously visualize relationships and distributions among all stock price variables. It provides a compact overview of how prices interact with each other.\n",
        "\n"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Strong linear relationships between all price pairs\n",
        "\n",
        "->Confirms that all prices move together under the same market conditions"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a significant relationship between the Open price and the Close price of Yes Bank stock.\n",
        "\n",
        "->This statement was derived from scatter plots and correlation heatmaps, which visually indicated a strong positive relationship.\n"
      ],
      "metadata": {
        "id": "x52MBHb02jXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: There is no significant relationship between open and close price\n",
        "\n",
        "Alternative Hypothesis: There is significant relationship between open and close price."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# TEST USED- PEARSON CORRELATION TEST"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "correlation, p_value=pearsonr(df['Open'],df['Close'])\n",
        "\n",
        "print(\"Correlation:\",correlation)\n",
        "print(\"p-values:\",p_value)\n",
        "\n",
        "if p_value<0.05:\n",
        "  print(\"Reject the null hypothesis, there is a significant relationship between open and close price\")\n",
        "else:\n",
        "  print(\"fail to reject the null hypothesis, there is no significant relationship between open and close price\")\n"
      ],
      "metadata": {
        "id": "iZNf4DTF3Wd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test was used to test the null hypothesis that there is no linear relationship between Open and Close prices. Since the p-value was significantly less than 0.05 and the correlation coefficient was high (r ≈ 0.98), the null hypothesis was rejected, confirming a strong and statistically significant positive relationship between the two variables.\n"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pearson correlation test was chosen to measure the strength and direction of the linear relationship between two continuous numerical variables — Open price and Close price\n",
        "\n",
        "-This test is appropriate for the dataset because:\n",
        "\n",
        "->Both variables are continuous and numerical, satisfying a key requirement of Pearson correlation.\n",
        "\n",
        "->The objective was to determine whether changes in the Open price are linearly associated with changes in the Close price.\n",
        "\n",
        "->Pearson correlation provides both a correlation coefficient (r) to quantify relationship strength and a p-value to test statistical significance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***statement***\n",
        "\n",
        "There is a significant difference between the monthly Open and Close prices of Yes Bank stock\n",
        "\n",
        "This statement was motivated by boxplots and line charts, which showed noticeable price movement within month"
      ],
      "metadata": {
        "id": "5EvXWinB8T61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: Mean Open price equal to Mean closing price\n",
        "\n",
        "Alternative hypothesis: Mean Open Price not equal to Mean closing price"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Paired (T-test)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "t_statistic, p_value=ttest_rel(df['Open'],df['Close'])\n",
        "\n",
        "print(\"t-statistics:\", t_statistic)\n",
        "print('P-value:',p_value)\n",
        "\n",
        "if p_value<0.05:\n",
        "  print(\"Reject the null hypothesis, there is a significant difference between the monthly open and close prices\")\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis, there is no significant difference between the open and closing prices\")"
      ],
      "metadata": {
        "id": "i0txbXVE9F3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paired Sample t-Test\n",
        "\n",
        "A paired sample t-test was used because Open and Close prices are dependent observations measured from the same time period, and the test evaluates whether their mean difference is statistically significant\n",
        "\n",
        "p-value interpretation:\n",
        "\n",
        "Since the p-value (0.825) is greater than the significance level (0.05), we fail to reject the null hypothesis. This suggests that there is no statistically significant difference between the monthly Open and Close prices of Yes Bank"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paired sample t-test was chosen because:\n",
        "\n",
        "->Open and Close prices are paired observations from the same month.\n",
        "\n",
        "->Each Open price is directly related to its corresponding Close price.\n",
        "\n",
        "->The objective was to test whether the mean difference between Open and Close prices is statistically significant.\n",
        "\n",
        "->The test is designed to compare two related samples, not independent groups"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "PUySaa_7_4xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here in the given dataset, it doesn't have any missing values, so no need to go for imputation techniques.\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6_8xHVhVA-33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to detect outliers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(df[['Open','High','Low','Close']])\n",
        "plt.title('boxplot')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-pOZteO1CoYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_col=['Open','High','Low','Close']\n",
        "\n",
        "Q1=df[price_col].quantile(0.25)\n",
        "Q3=df[price_col].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "\n",
        "lower_bound=Q1-(1.5*IQR)\n",
        "upper_bound=Q3+(1.5*IQR)\n",
        "\n",
        "print(\"Lower Bound:\\n\",lower_bound)\n",
        "print(\"Upper Bound:\\n\",upper_bound)\n",
        "\n"
      ],
      "metadata": {
        "id": "oAliIgoiBDG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capping\n",
        "df[price_col]=df[price_col].clip(lower=lower_bound,upper=upper_bound, axis=1 )"
      ],
      "metadata": {
        "id": "GOTWk7FeDgP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify outliers after treatment\n",
        "outliers_after = ((df[price_col] < lower_bound) | (df[price_col] > upper_bound)).sum()\n",
        "outliers_after\n"
      ],
      "metadata": {
        "id": "_uSh8U5lD-5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(df[price_col])\n",
        "plt.title(\"Boxplot After Outlier Treatment\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X5Cwx8R0EPic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers were first identified using visualization techniques, specifically boxplots, which provided a view of the data distribution and highlighted the presence of extreme values across all price-related columns\n",
        "\n",
        "After confirming the presence of outliers, the Interquartile Range (IQR) method was applied to statistically determine the lower and upper bounds for each price column\n",
        "\n",
        "Instead of removing the detected outliers, a capping (winsorization) technique was used to limit extreme values within the calculated IQR bounds. This approach was selected to avoid loss of important information, especially given the limited size of the dataset.\n",
        "\n",
        "Finally, boxplots were re-generated after applying capping to verify that the influence of outliers had been effectively reduced, ensuring the dataset was more stable and suitable for regression modeling."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding was not required for this regression task because the dataset contains only numerical features. The Date column was treated as a time-based feature and was either excluded or transformed into numerical components rather than encoded as a categorical variable"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new features was not mandatory for this regression task, as the existing price-related features already showed strong predictive power."
      ],
      "metadata": {
        "id": "fXlHAVcTQb1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns='Date', inplace=True)"
      ],
      "metadata": {
        "id": "QD9nilseJ1DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define features and target\n",
        "X = df[['Open', 'High', 'Low']]\n",
        "y = df['Close']"
      ],
      "metadata": {
        "id": "xUv9gxFHKaBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection was performed using correlation analysis. The columns Open, High, and Low were selected as independent features, while Close was chosen as the target variable. These feature columns exhibit a strong positive correlation with the target, indicating that they carry significant predictive information for estimating the closing price. Selecting highly correlated numerical features helps improve model performance and ensures that the regression model captures meaningful price relationships"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open, High, and Low prices were identified as the most important features because they exhibited strong positive correlation with the Close price and directly represent key aspects of market behavior. These features collectively capture price movement throughout the month, making them highly informative for predicting the closing price"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data did not need major transformation because the features already had a linear relationship with the target variable. Outliers were handled using the capping method. Since regression models do not strictly require normally distributed features, transformations like log or power transformation were not applied. Standardization was used only to bring all features to the same scale"
      ],
      "metadata": {
        "id": "YHIqnkANRV7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "\n",
        "# Features and target\n",
        "X = df[['Open', 'High', 'Low']]\n",
        "y = df['Close']\n",
        "\n",
        "# Fit and transform features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Convert back to dataframe\n",
        "X_scaled=pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "X_scaled.head()"
      ],
      "metadata": {
        "id": "lQlUJxNpRoEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Standardization (StandardScaler) to scale my data. This method converts all feature values to a similar scale by keeping the mean as 0 and standard deviation as 1. I used this because regression models work better when features are on the same scale. It also helps the model learn faster and gives more accurate results."
      ],
      "metadata": {
        "id": "DkBOqHY6THDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dimensionality reduction is not needed.\n",
        "\n",
        "The dataset contains only 5 columns and 185 rows, which is already small and easy to handle. All selected features (Open, High, Low) are directly relevant to predicting the Close price and do not cause high dimensional complexity. Applying dimensionality reduction techniques like PCA may reduce interpretability without providing any significant performance benefit."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train_test split-(80-20)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "P7csT2YSTvh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit only on training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use same scaler for test data\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "4oPBmdFuWGH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the train_test_split method.\n",
        "\n",
        "Why?\n",
        "\n",
        "It is simple and easy to use, especially for beginners.\n",
        "\n",
        "It randomly splits the dataset into training and testing data, reducing bias.\n",
        "\n",
        "It is widely used in machine learning for creating reliable model evaluation.\n",
        "\n",
        "This method helps ensure the model is trained and tested on different data.\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a regression problem where the target variable (Close price) is a continuous numerical value, not a category or class. The concept of data imbalance mainly applies to classification problems, where some classes have significantly fewer samples than others. Since this dataset aims to predict a numerical value and does not involve class labels, the notion of class imbalance does not apply here\n",
        "\n",
        "Why?\n",
        "\n",
        "The target classes are almost evenly distributed.\n",
        "\n",
        "No single class dominates the dataset.\n",
        "\n",
        "This means the model will not be biased toward one class"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr=LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "lr.fit(X_train_scaled,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred=lr.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "LOXkxNM0X2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "import numpy as np\n",
        "\n",
        "Lr_MAE=mean_absolute_error(y_test,y_pred)\n",
        "Lr_RMSE=np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "Lr_r2=r2_score(y_test,y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error:\",Lr_MAE)\n",
        "print(\"Root Mean Squared Error:\",Lr_RMSE)\n",
        "print(\"R2 Score:\",Lr_r2)"
      ],
      "metadata": {
        "id": "rtQmhfxDq6p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression was selected as a baseline model because it is simple, interpretable, and works well when there is a strong linear relationship between features and the target. In this dataset, Open, High, and Low prices show a strong positive correlation with the Close price, making Linear Regression a suitable starting point."
      ],
      "metadata": {
        "id": "pR2n9cFtYvNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = ['MAE','RMSE','R²']\n",
        "scores=[Lr_MAE,Lr_RMSE,Lr_r2]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(metrics,scores, color=['red','green','blue'])\n",
        "plt.title('Linear Regression evaluation metrics')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R² score appears smaller in the bar chart because it ranges between 0 and 1, while MAE and RMSE are measured in price units and have larger numerical values. The difference in scale causes the R² bar to look comparatively smaller, even though its value (0.99) indicates excellent model performance."
      ],
      "metadata": {
        "id": "nHYKPduJuafN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'fit_intercept': [True, False]}\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "grid_lr = GridSearchCV(lr,param_grid,cv=5,scoring='r2')\n",
        "grid_lr.fit(X_train_scaled,y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_lr_model = grid_lr.best_estimator_\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_lr_opt = best_lr_model.predict(X_test_scaled)\n",
        "\n",
        "print('Best Parameters:', grid_lr.best_params_)\n",
        "print('Best Score:', grid_lr.best_score_)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lr_opt[:5]"
      ],
      "metadata": {
        "id": "cSQCP0WfyGl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# comparison = pd.DataFrame({\n",
        "#     'Actual Close Price': y_test.values,\n",
        "#     'Predicted Close Price': y_pred_lr_opt\n",
        "# })\n",
        "\n",
        "# comparison.head()"
      ],
      "metadata": {
        "id": "_f1pL5DSyDYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technique Used: GridSearchCV\n",
        "\n",
        "GridSearchCV was chosen because Linear Regression has a limited number of hyperparameters. GridSearch systematically evaluates all parameter combinations and ensures optimal model selection using cross-validation."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, a slight improvement was observed after hyperparameter tuning.\n",
        "\n",
        "The R² score increased from 0.9913 to 0.9955, which indicates that the optimized model explains more variance in the closing price compared to the baseline mode"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "2KQjZ7sVzo-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "CPufi64L0CzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf[:5]"
      ],
      "metadata": {
        "id": "P0SYFjXd0Pi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "rf_r2 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Mean Absolute Error:\", rf_mae)\n",
        "print(\"Root Mean Squared Error:\", rf_rmse)\n",
        "print(\"R2 Score:\", rf_r2)"
      ],
      "metadata": {
        "id": "M8W-x8zK0HNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor is an ensemble learning model that builds multiple decision trees and combines their predictions. It is capable of capturing complex and non-linear relationships between features and the target variable."
      ],
      "metadata": {
        "id": "_q7sEfdI03JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = ['MAE', 'RMSE', 'R²']\n",
        "rf_scores = [rf_mae, rf_rmse, rf_r2]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(metrics, rf_scores, color=['red','green','blue'])\n",
        "plt.title('Random Forest Evaluation Metrics')\n",
        "plt.xlabel('metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_rf = {'n_estimators': [100, 200],\n",
        "                'max_depth': [None, 10, 20],\n",
        "                'min_samples_split': [2, 5]}\n",
        "\n",
        "grid_rf = GridSearchCV( estimator=RandomForestRegressor(random_state=42),\n",
        "                        param_grid=param_grid_rf,\n",
        "                        cv=5,\n",
        "                        scoring='r2',\n",
        "                        n_jobs=-1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf_model = grid_rf.best_estimator_\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf_opt = best_rf_model.predict(X_test)\n",
        "\n",
        "print('Best Parameters:', grid_rf.best_params_)\n",
        "print('Best Score:', grid_rf.best_score_)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf_opt[:5]"
      ],
      "metadata": {
        "id": "wwWmaI4y1eEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Actual Close Price': y_test.values,\n",
        "    'Predicted Close Price': y_pred_rf_opt\n",
        "})\n",
        "\n",
        "comparison.head()"
      ],
      "metadata": {
        "id": "0MTGi7aS1m12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV was used because it systematically evaluates multiple combinations of hyperparameters using cross-validation. Random Forest has several important tuning parameters (like n_estimators and max_depth), so GridSearch helps identify the best combination for improved performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, improvement was observed after applying hyperparameter tuning using GridSearchCV. The R² score increased from 0.9793 to 0.9891, indicating better model performance and improved variance explanation. The optimized parameters (increased n_estimators and controlled max_depth) helped the model generalize better and reduce overfitting. Overall, the tuned Random Forest model performs more accurately than the baseline model."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mean Absolute Error (MAE)\n",
        "\n",
        "\n",
        "*   MAE shows the average difference between the predicted closing price and the actual closing price.\n",
        "\n",
        "\n",
        "\n",
        "*   If MAE is low ,it means predictions are very close to real market prices. This helps investors, analysts, or financial planners make more accurate trading and investment decisions with lower financial risk.\n",
        "\n",
        "\n",
        "#### Root Mean Squared Error (RMSE)\n",
        "\n",
        "*   RMSE gives more importance to larger errors. It shows how serious large prediction mistakes are.\n",
        "*   In stock markets, large prediction errors can lead to heavy financial losses. A lower RMSE means the model avoids major price miscalculations\n",
        "\n",
        "#### R² Score\n",
        "\n",
        "\n",
        "\n",
        "*   R² shows how much of the variation in closing price is explained by the model.\n",
        "*   A high R² indicates strong predictive power. This improves confidence in forecasting stock trends, supporting better strategic decisions in investment planning.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I considered MAE, RMSE, and R² score for evaluating business impact.\n",
        "\n",
        "MAE and RMSE were important because they measure prediction errors — lower values reduce financial risk in stock price decisions.\n",
        "R² score was considered to check how well the model explains price variation — a higher R² increases confidence in forecasting and investment planning.\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected Linear Regression as the final prediction model. It achieved a lower MAE (4.98) and RMSE (8.52) compared to Random Forest, indicating smaller prediction errors. Additionally, it produced a higher R² score (0.9913), meaning it explains more variance in the closing price. Since it delivers better accuracy and performance metrics."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we used Linear Regression to predict the monthly closing price of Yes Bank stock. Linear Regression establishes a linear relationship between the independent variables (Open, High, Low) and the target variable (Close). Since the features were highly correlated with the closing price, the model achieved a high R² score.\n",
        "\n",
        "The main libraries used were Pandas and NumPy for data processing, Matplotlib and Seaborn for visualization, and Scikit-learn for model building, scaling, and evaluation."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project successfully developed a machine learning model to predict the monthly closing price of Yes Bank stock using historical price data. Through exploratory data analysis, statistical testing, outlier treatment, and feature selection, a strong linear relationship was identified between Open, High, Low, and Close prices. Two regression models were implemented and evaluated, and Linear Regression outperformed Random Forest with lower error values and a higher R² score (0.9913).\n",
        "\n",
        "The final model demonstrates high predictive accuracy and reliability, making it suitable for supporting financial forecasting and investment-related decision-making. Overall, the project follows a complete end-to-end machine learning workflow and provides meaningful business insights"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}